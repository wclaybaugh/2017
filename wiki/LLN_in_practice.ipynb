{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TL;DR\n",
    "The LLN promises that if we pile in more random numbers to an average (particularly if they are all independent draws from a fixed distribution), the average we happen to see will increase in precision and accuracy as we increase the sample size.\n",
    "\n",
    "This may seem odd: more randomness making for a more accurate result, but the idea is that with more random variables there are more paths to an accurate result than to an inaccurate one. Equally, with more random variables there's more of a chance that results that are randomly too low are balanced by results that are randomly too high.\n",
    "\n",
    "## Applying the LLN\n",
    "The Law of Large Numbers says the running mean of an infinitely long list of independent and not-too-wildly spread random variables 1) has a distribution- we'd record different means in different trials based on the particular values of each random variable we observed 2) the distribution of the possible running means gets narrower over time.\n",
    "\n",
    "A more refined version considered an infinitely long list of random variables *that all have the same mean $\\mu$*. Now, in addition to becoming narrower over time, the means we might see will close in on $\\mu$.\n",
    "\n",
    "Great. How can we use these facts to do practical things?\n",
    "\n",
    "### Precision and Accuracy \n",
    "The first version of the LLN tells us that the mean of a group of random varaibles gets more _precise_ as the group grows to infinity (as long as the included varaibles aren't too heavy-tailed). That is, if you and a friend both take draws from a large number of random variables the mean you calculate and the mean your friend calculates are probably pretty close together.\n",
    "\n",
    "The second, equal-means version of the LLN additionally says that the mean you calculate from whatever values the random variables happened to spit out is _accurate_. That is, the mean that you got (and the one your friend got) will both get closer and closer to the true mean $\\mu$.\n",
    "\n",
    "### A Common Use: Experiments\n",
    "Okay, but when in real life do we take the mean of a bunch of random numbers that all have the same mean? And if we know they all have the same mean, why wouldn't we know what the mean is in the first place?\n",
    "\n",
    "The common case here is when we make repeated draws from a particular distribution. For instance, we might be measuring the speed of light via an experiment with some particular equipment. Of course said experiment doesn't always give exactly the same read-out. Even if we don't know what distirbution the experiments's results follow we can reasonably believe that 1) said distribution has _some_ mean and 2) each run of the experiment is independent of the other. Then, by the LLN if we average the various experimental outputs we'll get closer and closer to the true average output. And if we want to get even closer, we can just run the experiment more times.\n",
    "\n",
    "#### Caveat\n",
    "It's worth mentioning that the above did not guarantee that the average of experimental results converges to the true speed of light. Getting the right speed of light depends on whether the experiment is such that its average result is the speed of light. LLN only promises that we'll find the average of the distribution of possible experimental results.\n",
    "\n",
    "### Another use: Simulation and Frequentism\n",
    "See the notebook \"Law of Large Numbers applied to simulation\" for more. But we'll state here that the LLN is what allows us to believe that we can find probabilites via simulations, or via long-run averages as in frequentist definitions of probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
